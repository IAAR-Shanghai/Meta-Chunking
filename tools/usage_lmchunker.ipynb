{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of using lmchunker package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/d2/zhaojihao/envs/mypypi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name_or_path='/mnt/data102_d2/huggingface/models/Qwen2-1.5B-Instruct' \n",
    "device_id = 6   \n",
    "device = torch.device(f'cuda:{device_id}' if torch.cuda.is_available() and torch.cuda.device_count() > device_id else 'cpu')  \n",
    "small_tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,trust_remote_code=True)  \n",
    "small_model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True).to(device)  \n",
    "small_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Segments the given text into chunks based on the specified method and parameters.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "necessary\n",
    "- text: Text that needs to be segmented\n",
    "- small_model: The small language model used for segmentation\n",
    "- small_tokenizer: The tokenizer used for text tokenization\n",
    "- language: en or zh\n",
    "\n",
    "optional\n",
    "- methodth: The LLM chunking method that needs to be used, ['ppl','ms','lumber_ms']\n",
    "- threshold: The threshold for controlling PPL Chunking is inversely proportional to the chunk length; the smaller the threshold, the shorter the chunk length.\n",
    "- dynamic_merge: no or yes\n",
    "- target_size: If dynamic_merge='yes', then the chunk length value needs to be set\n",
    "- batch_size: The length of a single document processed at a time, used to optimize GPU memory usage when processing longer documents\n",
    "- max_txt_size: The total context length that can be considered or the maximum length that the GPU memory can accommodate\n",
    "\n",
    "Returns:\n",
    "- List[str]: A list of segmented text chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.879 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 [[0, 1, 2], [3, 4], [5, 6, 7], [8, 9, 10], [11, 12], [13, 14, 15], [16]]\n",
      "The program execution time is: 1.938673973083496 seconds.\n",
      "Number 1:  2023-08-01 10:47，正文：通气会现场 来源：湖南高院7月31日，湖南高院联合省司法厅召开新闻通气会。湖南高院副院长杨翔，省委依法治省办成员、省司法厅党组成员、副厅长杨龙金通报2022年湖南省行政机关负责人出庭应诉有关情况，并发布5个典型案例。2022年，全省经人民法院通知出庭的行政机关负责人出庭应诉率提升至96.5%。\n",
      "Number 2:  杨翔介绍，从出庭应诉数量看，负责人出庭应诉意识普遍提升。2022年，全省法院共发出行政机关负责人出庭应诉通知书4228份，行政机关负责人到庭应诉4018件。\n",
      "Number 3:  行政机关负责人参加调查询问1117件，参与案件协调化解741件。与2021年相比，行政机关负责人到庭应诉和参加调查询问等案件增加2802件。从地区分布情况来看，全省各地经人民法院通知的行政机关负责人出庭应诉率均达到90%以上，较往年有明显提升。\n",
      "Number 4:  2022年，从行政管理领域看，全省法院制发负责人出庭应诉通知书的案件所涉行政管理领域较为集中，自然资源、社会保障、公安、市场监管等部门负责人出庭应诉的案件数量较多。从涉案行政行为看，被诉行为类型相对集中。排名前五的行政行为类型依次为行政征收或征用类案件、行政确认类案件、不履行法定职责类案件、行政处罚类案件及行政登记类案件。\n",
      "Number 5:  从出庭应诉负责人层级比例看，基层行政机关负责人出庭应诉占比较高。县市区及乡镇负责人出庭应诉数量占全部出庭应诉案件数的80.8%。\n",
      "Number 6:  杨龙金介绍，为进一步加强和完善负责人出庭应诉制度建设，省委依法治省办、省法院、省司法厅联合印发《关于进一步推进行政机关负责人出庭应诉的工作方案》（以下简称《工作方案》），推动省政府出台《湖南省行政应诉工作规定》并召开全省行政应诉工作会议，依托府院联动，推动行政机关负责人出庭应诉工作有序开展。湖南高院、省司法厅根据最高人民法院相关司法解释，在《工作方案》中统一了行政机关负责人出庭应诉的认定标准和计算方式，实现了全省负责人出庭应诉工作的标准化和规范化。同时，推动将行政机关负责人出庭应诉情况纳入省绩效考核、平安建设、市域社会治理等考核指标体系，进一步压实出庭应诉主体责任。\n",
      "Number 7:  《工作方案》还明确将行政机关负责人参与调解和解并实质化解争议的案件视为已履行出庭应诉义务，既提高了负责人出庭应诉的积极性，也有力维护了当事人合法权益，促进经济社会和谐稳定。\n"
     ]
    }
   ],
   "source": [
    "from lmchunker import chunker\n",
    "import json\n",
    "with open('data/example1.json', 'r', encoding='utf-8') as file:  \n",
    "    examples = json.load(file)\n",
    "language='zh' # en or zh\n",
    "text=examples[0][language] # Text that needs to be segmented\n",
    "\n",
    "chunks=chunker(text,small_model,small_tokenizer,language)\n",
    "i=1\n",
    "for chunk in chunks:\n",
    "    print(f'Number {i}: ', chunk)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.714 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ID 13\n",
      "The program execution time is: 4.001843690872192 seconds.\n",
      "Number 1:  2023-08-01 10:47，正文：通气会现场 来源：湖南高院7月31日，湖南高院联合省司法厅召开新闻通气会。 湖南高院副院长杨翔，省委依法治省办成员、省司法厅党组成员、副厅长杨龙金通报2022年湖南省行政机关负责人出庭应诉有关情况，并发布5个典型案例。 2022年，全省经人民法院通知出庭的行政机关负责人出庭应诉率提升至96.5%。 杨翔介绍，从出庭应诉数量看，负责人出庭应诉意识普遍提升。 2022年，全省法院共发出行政机关负责人出庭应诉通知书4228份，行政机关负责人到庭应诉4018件。 行政机关负责人参加调查询问1117件，参与案件协调化解741件。 与2021年相比，行政机关负责人到庭应诉和参加调查询问等案件增加2802件。 从地区分布情况来看，全省各地经人民法院通知的行政机关负责人出庭应诉率均达到90%以上，较往年有明显提升。 2022年，从行政管理领域看，全省法院制发负责人出庭应诉通知书的案件所涉行政管理领域较为集中，自然资源、社会保障、公安、市场监管等部门负责人出庭应诉的案件数量较多。 从涉案行政行为看，被诉行为类型相对集中。 排名前五的行政行为类型依次为行政征收或征用类案件、行政确认类案件、不履行法定职责类案件、行政处罚类案件及行政登记类案件。 从出庭应诉负责人层级比例看，基层行政机关负责人出庭应诉占比较高。 县市区及乡镇负责人出庭应诉数量占全部出庭应诉案件数的80.8%。\n",
      "Number 2:  杨龙金介绍，为进一步加强和完善负责人出庭应诉制度建设，省委依法治省办、省法院、省司法厅联合印发《关于进一步推进行政机关负责人出庭应诉的工作方案》（以下简称《工作方案》），推动省政府出台《湖南省行政应诉工作规定》并召开全省行政应诉工作会议，依托府院联动，推动行政机关负责人出庭应诉工作有序开展。 湖南高院、省司法厅根据最高人民法院相关司法解释，在《工作方案》中统一了行政机关负责人出庭应诉的认定标准和计算方式，实现了全省负责人出庭应诉工作的标准化和规范化。 同时，推动将行政机关负责人出庭应诉情况纳入省绩效考核、平安建设、市域社会治理等考核指标体系，进一步压实出庭应诉主体责任。 《工作方案》还明确将行政机关负责人参与调解和解并实质化解争议的案件视为已履行出庭应诉义务，既提高了负责人出庭应诉的积极性，也有力维护了当事人合法权益，促进经济社会和谐稳定。\n"
     ]
    }
   ],
   "source": [
    "from lmchunker.modules import lumberchunker\n",
    "import json\n",
    "with open('data/example1.json', 'r', encoding='utf-8') as file:  \n",
    "    examples = json.load(file)\n",
    "### zhipuai needs to be installed: pip install zhipuai\n",
    "api_name='zhipuai' # The model name of the API that needs to be called\n",
    "api_configure={\"api_key\":\"your_api_key\",\"model_name\":\"glm-4-0520\"} # Need to fill in according to the model name\n",
    "language='zh' # en or zh\n",
    "text=examples[0][language] # Text that needs to be segmented\n",
    "dynamic_merge='no' # no or yes\n",
    "target_size=200 # If dynamic_merge='yes', then the chunk length value needs to be set\n",
    "chunks=lumberchunker(api_name,api_configure,language,text,dynamic_merge,target_size)\n",
    "i=1\n",
    "for chunk in chunks:\n",
    "    print(f'Number {i}: ', chunk)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "model_name = \"/d2/zhaojihao/models/propositionizer-wiki-flan-t5-large\"\n",
    "device_id = 0  \n",
    "device = torch.device(f'cuda:{device_id}' if torch.cuda.is_available() and torch.cuda.device_count() > device_id else 'cpu')  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: . Section: . Content:  Waldrada of Lotharingia\n",
      "Waldrada was the mistress, and later the wife, of Lothair II of Lotharingia. Biography\n",
      "Waldrada's family origin is uncertain. The prolific 19th-century French writer Baron Ernouf suggested that Waldrada was of noble Gallo-Roman descent, sister of Thietgaud, the bishop of Trier, and niece of Gunther, archbishop of Cologne. However, these suggestions are not supported by any evidence, and more recent studies have instead suggested she was of relatively undistinguished social origins, though still from an aristocratic milieu.\n",
      "[ERROR] Failed to parse output text as JSON.\n",
      "Title: . Section: . Content: The Vita Sancti Deicoli states that Waldrada was related to Eberhard II, Count of Nordgau (included Strasbourg) and the family of Etichonids, though this is a late 10th-century source and so may not be entirely reliable on this question.In 855 the Carolingian king Lothar II married Teutberga, a Carolingian aristocrat and the daughter of Bosonid Boso the Elder. The marriage was arranged by Lothar's father Lothar I for political reasons. It is very probable that Waldrada was already Lothar II's mistress at this time.Teutberga was allegedly not capable of bearing children and Lothar's reign was chiefly occupied by his efforts to obtain an annulment of their marriage, and his relations with his uncles Charles the Bald and Louis the German were influenced by his desire to obtain their support for this endeavour. Lothair, whose desire for annulment was arguably prompted by his affection for Waldrada, put away Teutberga.\n",
      "Title: . Section: . Content: However, Hucbert took up arms on his sister's behalf, and after she had submitted successfully to the ordeal of water, Lothair was compelled to restore her in 858. Still pursuing his purpose, he won the support of his brother, Emperor Louis II, by a cession of lands and obtained the consent of the local clergy to the annulment and to his marriage with Waldrada, which took place in 862. However, Pope Nicholas I was suspicious of this and sent legates to investigate at the Council of Metz in 863. The Council found in favour of Lothair's divorce, which led to rumours that the papal legates may have bribed and thus meant that Nicholas order Lothair to take Teutberga back or face excommunication. With the support of Charles the Bald and Louis the German, Teutberga appealed the annulment to Pope Nicholas. Nicholas refused to recognize the annulment and excommunicated Waldrada in 866, forcing Lothair to abandon Waldrada in favour of Teutberga.\n",
      "Title: . Section: . Content: Lothair accepted this begrudgingly for a time, but shortly afterward at the end of 867 Pope Nicholas I died. Thus, Lothair began to seek the permission of the newly appointed Pope Adrian II to again put Teutberga aside and marry Waldrada, riding to Rome to speak with him on the matter in 869. However, on his way home, Lothair died. Children\n",
      "Waldrada and Lothair II had some sons and probably three daughters, all of whom were declared illegitimate:\n",
      "\n",
      "Hugh (c. 855–895), Duke of Alsace (867–885)\n",
      "Gisela (c. 865–908), who in 883 married Godfrey, the Viking leader ruling in Frisia, who was murdered in 885\n",
      "Bertha (c. 863–925), who married Theobald of Arles (c. 854–895), count of Arles, nephew of Teutberga. They had two sons, Hugh of Italy and Boso of Tuscany.\n",
      "Title: . Section: . Content: After Theobald's death, between 895 and 898 she married Adalbert II of Tuscany (c. 875–915) They had at least three children: Guy, who succeeded his father as count and duke of Lucca and margrave of Tuscany, Lambert succeeded his brother in 929, but lost the titles in 931 to his half-brother Boso of Tuscany, and Ermengard. Ermengarde (d. 90?) Odo (d. c.879)\n",
      "Number 1:  The Vita Sancti Deicoli states that Waldrada was related to Eberhard II, Count of Nordgau, and the family of Etichonids.\n",
      "Number 2:  Eberhard II was the Count of Nordgau.\n",
      "Number 3:  Nordgau included Strasbourg.\n",
      "Number 4:  The Vita Sancti Deicoli is a late 10th-century source.\n",
      "Number 5:  The Vita Sancti Deicoli may not be entirely reliable on this question.\n",
      "Number 6:  In 855, Lothar II married Teutberga.\n",
      "Number 7:  Teutberga was a Carolingian aristocrat.\n",
      "Number 8:  Teutberga was the daughter of Bosonid Boso the Elder.\n",
      "Number 9:  The marriage between Lothar II and Teutberga was arranged by Lothar I for political reasons.\n",
      "Number 10:  It is probable that Waldrada was already Lothar II's mistress at this time.\n",
      "Number 11:  Teutberga was allegedly not capable of bearing children.\n",
      "Number 12:  Lothar II's reign was chiefly occupied by his efforts to obtain an annulment of their marriage.\n",
      "Number 13:  Lothar II's relations with his uncles Charles the Bald and Louis the German were influenced by his desire to obtain their support for their annulment.\n",
      "Number 14:  Lothair's desire for annulment was arguably prompted by his affection for Waldrada.\n",
      "Number 15:  Lothair put away Teutberga.\n",
      "Number 16:  Hucbert took up arms on his sister's behalf.\n",
      "Number 17:  Hucbert's sister submitted successfully to the ordeal of water.\n",
      "Number 18:  Lothair was compelled to restore Hucbert's sister in 858.\n",
      "Number 19:  Lothair won the support of his brother, Emperor Louis II, by a cession of lands.\n",
      "Number 20:  Lothair obtained the consent of the local clergy to the annulment and to his marriage with Waldrada.\n",
      "Number 21:  The annulment and marriage with Waldrada took place in 862.\n",
      "Number 22:  Pope Nicholas I was suspicious of Lothair's intentions.\n",
      "Number 23:  Pope Nicholas I sent legates to investigate at the Council of Metz in 863.\n",
      "Number 24:  The Council of Metz found in favour of Lothair's divorce.\n",
      "Number 25:  Rumors suggested that the papal legates may have bribed.\n",
      "Number 26:  Pope Nicholas I ordered Lothair to take Teutberga back or face excommunication.\n",
      "Number 27:  Charles the Bald and Louis the German supported Teutberga.\n",
      "Number 28:  Teutberga appealed the annulment to Pope Nicholas.\n",
      "Number 29:  Pope Nicholas refused to recognize the annulment.\n",
      "Number 30:  Pope Nicholas excommunicated Waldrada in 866.\n",
      "Number 31:  Lothair was forced to abandon Waldrada in favour of Teutberga.\n",
      "Number 32:  Lothair accepted Pope Nicholas I's marriage proposal begrudgingly for a time.\n",
      "Number 33:  Pope Nicholas I died at the end of 867.\n",
      "Number 34:  Lothair began to seek the permission of Pope Adrian II to marry Waldrada.\n",
      "Number 35:  Pope Adrian II was newly appointed.\n",
      "Number 36:  Lothair rode to Rome to speak with Pope Adrian II on the matter in 869.\n",
      "Number 37:  On Lothair's way home, he died.\n",
      "Number 38:  Lothair and Waldrada had some sons and probably three daughters.\n",
      "Number 39:  All of the children were declared illegitimate.\n",
      "Number 40:  Hugh was the Duke of Alsace from 855 to 895.\n",
      "Number 41:  Gisela was the Duke of Alsace from 867 to 885.\n",
      "Number 42:  Gisela married Godfrey in 883.\n",
      "Number 43:  Godfrey was the Viking leader ruling in Frisia.\n",
      "Number 44:  Godfrey was murdered in 885.\n",
      "Number 45:  Bertha was the daughter of Hugh and Lothair II.\n",
      "Number 46:  Bertha was born around 863 to 925.\n",
      "Number 47:  Bertha married Theobald of Arles.\n",
      "Number 48:  Theobald of Arles was the count of Arles from 854 to 895.\n",
      "Number 49:  Theobald of Arles was the nephew of Teutberga.\n",
      "Number 50:  Lothair and Theobald of Arles had two sons, Hugh of Italy and Boso of Tuscany.\n",
      "Number 51:  Theobald died.\n",
      "Number 52:  Between 895 and 898, Theobald married Adalbert II of Tuscany.\n",
      "Number 53:  Adalbert II of Tuscany lived between 875 and 915.\n",
      "Number 54:  Theobald and Adalbert II of Tuscany had at least three children.\n",
      "Number 55:  Guy succeeded his father as count and duke of Lucca and margrave of Tuscany.\n",
      "Number 56:  Lambert succeeded his brother in 929.\n",
      "Number 57:  Lambert lost the titles in 931 to his half-brother Boso of Tuscany.\n",
      "Number 58:  Ermengarde was one of the children.\n",
      "Number 59:  Ermengarde died in 90.\n",
      "Number 60:  Odo was one of the children.\n",
      "Number 61:  Odo died around 879.\n"
     ]
    }
   ],
   "source": [
    "from lmchunker.modules import dense_x_retrieval\n",
    "import json\n",
    "with open('data/example1.json', 'r', encoding='utf-8') as file:  \n",
    "    examples = json.load(file)\n",
    "language='en' # At present, the model of this method is only applicable to English texts\n",
    "text=examples[0][language] # Text that needs to be segmented\n",
    "title=''\n",
    "section=''\n",
    "target_size=256  # This model can only accept a maximum length of 512, but longer texts tend to make it difficult for the model to extract effective information.\n",
    "chunks=dense_x_retrieval(tokenizer,model,text,title,section,target_size)\n",
    "i=1\n",
    "for chunk in chunks:\n",
    "    print(f'Number {i}: ', chunk)\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypypi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
